{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDOaOtVZ9I7G2P0z2NhpLJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arzhrd/Basketball-Player-Detail-Using-Computer-Vision/blob/main/Basketball_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Configure API Keys and check for GPU\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# Load API keys from Colab secrets\n",
        "try:\n",
        "    os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "    os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get(\"ROBOFLOW_API_KEY\")\n",
        "    print(\"API keys loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"Could not load API keys. Please set them up in Colab Secrets (ğŸ”‘).\")\n",
        "    print(\"Required secrets: 'HF_TOKEN' and 'ROBOFLOW_API_KEY'\")\n",
        "\n",
        "# Check for GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Set home directory\n",
        "HOME = Path.cwd()\n",
        "print(\"HOME:\", HOME)\n",
        "\n",
        "# Set ONNX provider to use GPU\n",
        "os.environ[\"ONNXRUNTIME_EXECUTION_PROVIDERS\"] = \"[CUDAExecutionProvider]\"\n",
        "\n",
        "# 2. Install SAM2 (Segment Anything Model 2) for tracking\n",
        "!git clone https://github.com/Gy920/segment-anything-2-real-time.git\n",
        "%cd {HOME}/segment-anything-2-real-time\n",
        "!pip install -e . -q\n",
        "!python setup.py build_ext --inplace\n",
        "!(cd checkpoints && bash download_ckpts.sh)\n",
        "%cd {HOME}\n",
        "\n",
        "# 3. Install all other required Python packages\n",
        "!pip install -q gdown inference-gpu supervision transformers num2words\n",
        "!pip install -q git+https://github.com/roboflow/sports.git@feat/basketball\n",
        "!pip install -q flash-attn --no-build-isolation\n",
        "\n",
        "print(\"\\nâœ… All installations are complete.\")"
      ],
      "metadata": {
        "id": "T5WDXGLphaGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c2a7d4-3a38-49bc-9302-780b82928c65"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API keys loaded successfully.\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "HOME: /content\n",
            "Cloning into 'segment-anything-2-real-time'...\n",
            "remote: Enumerating objects: 406, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 406 (delta 65), reused 56 (delta 56), pack-reused 313 (from 2)\u001b[K\n",
            "Receiving objects: 100% (406/406), 79.43 MiB | 30.52 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n",
            "/content/segment-anything-2-real-time\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mBuilding editable for SAM-\u001b[0m\u001b[1;32m2\u001b[0m\u001b[32m \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building editable for SAM-2\u001b[0m\u001b[31m\n",
            "\u001b[0m  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (SAM-2)\u001b[0m\u001b[31m\n",
            "\u001b[0mW1026 16:30:01.344000 3133 torch/utils/cpp_extension.py:118] No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "running build_ext\n",
            "W1026 16:30:01.631000 3133 torch/utils/cpp_extension.py:615] Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "W1026 16:30:01.720000 3133 torch/utils/cpp_extension.py:507] The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.6). Most likely this shouldn't be a problem.\n",
            "W1026 16:30:01.721000 3133 torch/utils/cpp_extension.py:517] There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\n",
            "building 'sam2._C' extension\n",
            "creating build/temp.linux-x86_64-cpython-312/sam2/csrc\n",
            "W1026 16:30:01.996000 3133 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "W1026 16:30:01.996000 3133 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/segment-anything-2-real-time/setup.py\", line 56, in <module>\n",
            "    setup(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/__init__.py\", line 117, in setup\n",
            "    return distutils.core.setup(**attrs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/core.py\", line 183, in setup\n",
            "    return run_commands(dist)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/core.py\", line 199, in run_commands\n",
            "    dist.run_commands()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/dist.py\", line 954, in run_commands\n",
            "    self.run_command(cmd)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/dist.py\", line 991, in run_command\n",
            "    super().run_command(command)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/dist.py\", line 973, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/command/build_ext.py\", line 98, in run\n",
            "    _build_ext.run(self)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/command/build_ext.py\", line 359, in run\n",
            "    self.build_extensions()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/cpp_extension.py\", line 1072, in build_extensions\n",
            "    build_ext.build_extensions(self)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/command/build_ext.py\", line 476, in build_extensions\n",
            "    self._build_extensions_serial()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/command/build_ext.py\", line 502, in _build_extensions_serial\n",
            "    self.build_extension(ext)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/command/build_ext.py\", line 263, in build_extension\n",
            "    _build_ext.build_extension(self, ext)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/Cython/Distutils/build_ext.py\", line 135, in build_extension\n",
            "    super(build_ext, self).build_extension(ext)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/command/build_ext.py\", line 557, in build_extension\n",
            "    objects = self.compiler.compile(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/ccompiler.py\", line 606, in compile\n",
            "    self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/cpp_extension.py\", line 750, in unix_wrap_single_compile\n",
            "    cflags = unix_cuda_flags(cflags)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/cpp_extension.py\", line 717, in unix_cuda_flags\n",
            "    cflags + _get_cuda_arch_flags(cflags))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/cpp_extension.py\", line 2445, in _get_cuda_arch_flags\n",
            "    arch_list[-1] += '+PTX'\n",
            "    ~~~~~~~~~^^^^\n",
            "IndexError: list index out of range\n",
            "Downloading sam2.1_hiera_tiny.pt checkpoint...\n",
            "--2025-10-26 16:30:05--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_tiny.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 99.84.118.30, 99.84.118.117, 99.84.118.60, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|99.84.118.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 156008466 (149M) [application/vnd.snesdev-page-table]\n",
            "Saving to: â€˜sam2.1_hiera_tiny.ptâ€™\n",
            "\n",
            "sam2.1_hiera_tiny.p 100%[===================>] 148.78M   280MB/s    in 0.5s    \n",
            "\n",
            "2025-10-26 16:30:05 (280 MB/s) - â€˜sam2.1_hiera_tiny.ptâ€™ saved [156008466/156008466]\n",
            "\n",
            "Downloading sam2.1_hiera_small.pt checkpoint...\n",
            "--2025-10-26 16:30:05--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 99.84.118.30, 99.84.118.117, 99.84.118.60, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|99.84.118.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 184416285 (176M) [application/vnd.snesdev-page-table]\n",
            "Saving to: â€˜sam2.1_hiera_small.ptâ€™\n",
            "\n",
            "sam2.1_hiera_small. 100%[===================>] 175.87M   254MB/s    in 0.7s    \n",
            "\n",
            "2025-10-26 16:30:06 (254 MB/s) - â€˜sam2.1_hiera_small.ptâ€™ saved [184416285/184416285]\n",
            "\n",
            "Downloading sam2.1_hiera_base_plus.pt checkpoint...\n",
            "--2025-10-26 16:30:06--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_base_plus.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 99.84.118.30, 99.84.118.117, 99.84.118.60, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|99.84.118.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 323606802 (309M) [application/vnd.snesdev-page-table]\n",
            "Saving to: â€˜sam2.1_hiera_base_plus.ptâ€™\n",
            "\n",
            "sam2.1_hiera_base_p 100%[===================>] 308.62M   284MB/s    in 1.1s    \n",
            "\n",
            "2025-10-26 16:30:07 (284 MB/s) - â€˜sam2.1_hiera_base_plus.ptâ€™ saved [323606802/323606802]\n",
            "\n",
            "Downloading sam2.1_hiera_large.pt checkpoint...\n",
            "--2025-10-26 16:30:07--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 99.84.118.30, 99.84.118.117, 99.84.118.60, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|99.84.118.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 898083611 (856M) [application/vnd.snesdev-page-table]\n",
            "Saving to: â€˜sam2.1_hiera_large.ptâ€™\n",
            "\n",
            "sam2.1_hiera_large. 100%[===================>] 856.48M   253MB/s    in 3.4s    \n",
            "\n",
            "2025-10-26 16:30:11 (251 MB/s) - â€˜sam2.1_hiera_large.ptâ€™ saved [898083611/898083611]\n",
            "\n",
            "All checkpoints are downloaded successfully.\n",
            "/content\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.1/190.1 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.5/95.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m258.7/258.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.7/160.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m292.3/292.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pybase64 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
            "typeguard 4.4.4 requires typing_extensions>=4.14.0, but you have typing-extensions 4.12.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sports (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "âœ… All installations are complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Download sample videos and fonts\n",
        "SOURCE_VIDEO_DIRECTORY = HOME / \"source\"\n",
        "!gdown -q https://drive.google.com/drive/folders/1eDJYqQ77Fytz15tKGdJCMeYSgmoQ-2-H -O {SOURCE_VIDEO_DIRECTORY} --folder\n",
        "!gdown -q https://drive.google.com/drive/folders/1RBjpI5Xleb58lujeusxH0W5zYMMA4ytO -O {HOME / \"fonts\"} --folder\n",
        "print(\"Sample videos and fonts downloaded.\")\n",
        "\n",
        "# 2. Define the source video path you want to process\n",
        "# You can change the filename to process a different clip from the `source` directory\n",
        "SOURCE_VIDEO_PATH = SOURCE_VIDEO_DIRECTORY / \"boston-celtics-new-york-knicks-game-1-q1-04.28-04.20.mp4\"\n",
        "\n",
        "# 3. Define Team Rosters and Colors\n",
        "TEAM_ROSTERS = {\n",
        "  \"New York Knicks\": {\n",
        "    \"55\": \"Hukporti\", \"1\": \"Payne\", \"0\": \"Wright\", \"11\": \"Brunson\", \"3\": \"Hart\",\n",
        "    \"32\": \"Towns\", \"44\": \"Shamet\", \"25\": \"Bridges\", \"2\": \"McBride\",\n",
        "    \"23\": \"Robinson\", \"8\": \"Anunoby\", \"4\": \"Dadiet\", \"5\": \"Achiuwa\", \"13\": \"Kolek\"\n",
        "  },\n",
        "  \"Boston Celtics\": {\n",
        "    \"42\": \"Horford\", \"55\": \"Scheierman\", \"9\": \"White\", \"20\": \"Davison\",\n",
        "    \"7\": \"Brown\", \"0\": \"Tatum\", \"27\": \"Walsh\", \"4\": \"Holiday\", \"8\": \"Porzingis\",\n",
        "    \"40\": \"Kornet\", \"88\": \"Queta\", \"11\": \"Pritchard\", \"30\": \"Hauser\",\n",
        "    \"12\": \"Craig\", \"26\": \"Tillman\"\n",
        "  }\n",
        "}\n",
        "\n",
        "TEAM_COLORS = {\n",
        "    \"New York Knicks\": \"#006BB6\",\n",
        "    \"Boston Celtics\": \"#007A33\"\n",
        "}"
      ],
      "metadata": {
        "id": "0GRLc11mhaue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6bcec6-be66-41be-bda6-bc5f0ea8f291"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample videos and fonts downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "from inference import get_model\n",
        "import torch\n",
        "\n",
        "# 1. Load Player and Number Detection Model (RF-DETR)\n",
        "PLAYER_DETECTION_MODEL_ID = \"basketball-player-detection-3-ycjdo/4\"\n",
        "PLAYER_DETECTION_MODEL = get_model(model_id=PLAYER_DETECTION_MODEL_ID)\n",
        "\n",
        "# 2. Load Player Tracking Model (SAM2.1)\n",
        "# We MUST change to the sam2 directory *before* importing from it.\n",
        "%cd {HOME}/segment-anything-2-real-time\n",
        "from sam2.build_sam import build_sam2_camera_predictor\n",
        "\n",
        "SAM2_CHECKPOINT = \"checkpoints/sam2.1_hiera_large.pt\"\n",
        "SAM2_CONFIG = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "sam_predictor = build_sam2_camera_predictor(SAM2_CONFIG, SAM2_CHECKPOINT)\n",
        "%cd {HOME} # Change back to the home directory\n",
        "\n",
        "# 3. Load Jersey Number Recognition Model (SmolVLM2)\n",
        "NUMBER_RECOGNITION_MODEL_ID = \"basketball-jersey-numbers-ocr/3\"\n",
        "NUMBER_RECOGNITION_MODEL = get_model(model_id=NUMBER_RECOGNITION_MODEL_ID)\n",
        "NUMBER_RECOGNITION_MODEL_PROMPT = \"Read the number.\"\n",
        "\n",
        "print(\"\\nâœ… All models loaded successfully.\")"
      ],
      "metadata": {
        "id": "YvQFQFVMh1fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "from sports.common.team import TeamClassifier\n",
        "\n",
        "# Class IDs for different player-related detections\n",
        "PLAYER_CLASS_IDS = [3, 4, 5, 6, 7]\n",
        "\n",
        "def shrink_boxes(xyxy: np.ndarray, scale: float) -> np.ndarray:\n",
        "    \"\"\"Shrinks bounding boxes to focus on the jersey.\"\"\"\n",
        "    x1, y1, x2, y2 = xyxy[:, 0], xyxy[:, 1], xyxy[:, 2], xyxy[:, 3]\n",
        "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "    w, h = (x2 - x1) * scale, (y2 - y1) * scale\n",
        "    new_x1, new_y1 = cx - w / 2, cy - h / 2\n",
        "    new_x2, new_y2 = cx + w / 2, cy + h / 2\n",
        "    return np.stack([new_x1, new_y1, new_x2, new_y2], axis=1)\n",
        "\n",
        "# 1. Collect player crops from all videos to build a training set\n",
        "crops = []\n",
        "for video_path in sv.list_files_with_extensions(SOURCE_VIDEO_DIRECTORY, extensions=[\"mp4\"]):\n",
        "    frame_generator = sv.get_video_frames_generator(source_path=str(video_path), stride=30)\n",
        "    for frame in tqdm(frame_generator, desc=f\"Processing {video_path.name}\"):\n",
        "        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.4, iou_threshold=0.9, class_agnostic_nms=True)[0]\n",
        "        detections = sv.Detections.from_inference(result)\n",
        "        detections = detections[np.isin(detections.class_id, PLAYER_CLASS_IDS)]\n",
        "        boxes = shrink_boxes(xyxy=detections.xyxy, scale=0.4)\n",
        "        for box in boxes:\n",
        "            crops.append(sv.crop_image(frame, box))\n",
        "\n",
        "# 2. Train the team classifier and predict teams for the collected crops\n",
        "team_classifier = TeamClassifier(device=\"cuda\")\n",
        "team_classifier.fit(crops)\n",
        "teams = team_classifier.predict(crops)\n",
        "\n",
        "# 3. Display the results of clustering for manual verification\n",
        "team_0 = [crop for crop, team in zip(crops, teams) if team == 0]\n",
        "team_1 = [crop for crop, team in zip(crops, teams) if team == 1]\n",
        "\n",
        "print(\"--- CLUSTER 0 ---\")\n",
        "sv.plot_images_grid(images=team_0[:20], grid_size=(2, 10), size=(10, 2))\n",
        "print(\"\\n--- CLUSTER 1 ---\")\n",
        "sv.plot_images_grid(images=team_1[:20], grid_size=(2, 10), size=(10, 2))"
      ],
      "metadata": {
        "id": "bFqO0BPN6cw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. MANUALLY ASSIGN TEAM NAMES BASED ON THE GRIDS ABOVE\n",
        "# Look at the images for Cluster 0 and Cluster 1 and assign the correct team name.\n",
        "# Uncomment the correct dictionary.\n",
        "\n",
        "TEAM_NAMES = {\n",
        "    0: \"New York Knicks\",\n",
        "    1: \"Boston Celtics\",\n",
        "}\n",
        "\n",
        "# TEAM_NAMES = {\n",
        "#     0: \"Boston Celtics\",\n",
        "#     1: \"New York Knicks\",\n",
        "# }\n",
        "\n",
        "print(\"Team names assigned:\")\n",
        "print(f\"Cluster 0 -> {TEAM_NAMES[0]}\")\n",
        "print(f\"Cluster 1 -> {TEAM_NAMES[1]}\")"
      ],
      "metadata": {
        "id": "uJUsCYT3tryl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell contains helper classes and functions needed for the main loop.\n",
        "# It includes the PropertyValidator for confirming numbers and functions for mask conversion.\n",
        "from typing import Dict, List, Optional, Union, Iterable, Tuple\n",
        "import cv2\n",
        "\n",
        "def xyxy_to_mask(boxes: np.ndarray, resolution_wh: Tuple[int, int]) -> np.ndarray:\n",
        "    width, height = resolution_wh\n",
        "    n = boxes.shape[0]\n",
        "    masks = np.zeros((n, height, width), dtype=bool)\n",
        "    for i, (x_min, y_min, x_max, y_max) in enumerate(boxes):\n",
        "        x_min, y_min = max(0, int(x_min)), max(0, int(y_min))\n",
        "        x_max, y_max = min(width - 1, int(x_max)), min(height - 1, int(y_max))\n",
        "        if x_max >= x_min and y_max >= y_min:\n",
        "            masks[i, y_min:y_max + 1, x_min:x_max + 1] = True\n",
        "    return masks\n",
        "\n",
        "def coords_above_threshold(matrix: np.ndarray, threshold: float) -> List[Tuple[int, int]]:\n",
        "    rows, cols = np.where(np.asarray(matrix) > threshold)\n",
        "    pairs = list(zip(rows.tolist(), cols.tolist()))\n",
        "    pairs.sort(key=lambda rc: matrix[rc[0], rc[1]], reverse=True)\n",
        "    return pairs\n",
        "\n",
        "def filter_segments_by_distance(mask: np.ndarray, distance_threshold: float = 300) -> np.ndarray:\n",
        "    mask_uint8 = mask.astype(np.uint8)\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_uint8, connectivity=8)\n",
        "    if num_labels <= 1: return mask.copy()\n",
        "    main_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
        "    main_centroid = centroids[main_label]\n",
        "    filtered_mask = np.zeros_like(mask, dtype=bool)\n",
        "    for label in range(1, num_labels):\n",
        "        if np.linalg.norm(centroids[label] - main_centroid) <= distance_threshold:\n",
        "            filtered_mask[labels == label] = True\n",
        "    return filtered_mask\n",
        "\n",
        "Value = Union[int, str, None]\n",
        "class PropertyValidator:\n",
        "    def __init__(self, n_consecutive: int):\n",
        "        self.n = n_consecutive\n",
        "        self._streak: Dict[int, int] = {}\n",
        "        self._last: Dict[int, Optional[str]] = {}\n",
        "        self._validated: Dict[int, Optional[str]] = {}\n",
        "\n",
        "    def _normalize(self, value: Value) -> Optional[str]:\n",
        "        if value is None: return None\n",
        "        s = str(value).strip()\n",
        "        return s if s else None\n",
        "\n",
        "    def update(self, tracker_ids: List[int], values: List[Value]):\n",
        "        for tid, raw in zip(tracker_ids, values):\n",
        "            if tid in self._validated and self._validated.get(tid) is not None: continue\n",
        "            val = self._normalize(raw)\n",
        "            if val is None:\n",
        "                self._streak[tid] = 0\n",
        "                continue\n",
        "            if self._last.get(tid) == val:\n",
        "                self._streak[tid] = self._streak.get(tid, 0) + 1\n",
        "            else:\n",
        "                self._streak[tid] = 1\n",
        "                self._last[tid] = val\n",
        "            if self._streak.get(tid, 0) >= self.n:\n",
        "                self._validated[tid] = self._last.get(tid)\n",
        "\n",
        "    def get_validated(self, tracker_ids: Iterable[int]) -> List[Optional[str]]:\n",
        "        return [self._validated.get(tid) for tid in tracker_ids]\n",
        "\n",
        "print(\"Helper utilities defined.\")"
      ],
      "metadata": {
        "id": "-GtaePfptr0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the main processing loop. It will take a few minutes to run.\n",
        "frames_history = []\n",
        "detections_history = []\n",
        "NUMBER_CLASS_ID = 2\n",
        "\n",
        "# Initialize validators\n",
        "number_validator = PropertyValidator(n_consecutive=3)\n",
        "team_validator = PropertyValidator(n_consecutive=1)\n",
        "\n",
        "# 1. Process the first frame to initialize trackers\n",
        "frame_generator = sv.get_video_frames_generator(str(SOURCE_VIDEO_PATH))\n",
        "frame = next(frame_generator)\n",
        "\n",
        "# Detect players and determine their teams\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.4, iou_threshold=0.9, class_agnostic_nms=True)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "detections = detections[np.isin(detections.class_id, PLAYER_CLASS_IDS)]\n",
        "TRACKER_IDS = list(range(1, len(detections.class_id) + 1))\n",
        "boxes = shrink_boxes(xyxy=detections.xyxy, scale=0.4)\n",
        "crops = [sv.crop_image(frame, box) for box in boxes]\n",
        "TEAMS = np.array(team_classifier.predict(crops))\n",
        "team_validator.update(tracker_ids=TRACKER_IDS, values=TEAMS)\n",
        "\n",
        "# Prompt SAM2.1 tracker with the initial player detections\n",
        "with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "    sam_predictor.load_first_frame(frame)\n",
        "    for xyxy, tracker_id in zip(detections.xyxy, TRACKER_IDS):\n",
        "        sam_predictor.add_new_prompt(frame_idx=0, obj_id=tracker_id, bbox=np.array([xyxy]))\n",
        "\n",
        "# 2. Loop through the rest of the video frames\n",
        "frame_generator = sv.get_video_frames_generator(str(SOURCE_VIDEO_PATH))\n",
        "for index, frame in tqdm(enumerate(frame_generator), desc=\"Processing video\"):\n",
        "    frame_h, frame_w, *_ = frame.shape\n",
        "\n",
        "    # Track players\n",
        "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "        tracker_ids, mask_logits = sam_predictor.track(frame)\n",
        "        masks = (mask_logits > 0.0).cpu().numpy().squeeze().astype(bool)\n",
        "        player_masks = np.array([filter_segments_by_distance(mask) for mask in masks])\n",
        "        player_detections = sv.Detections(\n",
        "            xyxy=sv.mask_to_xyxy(masks=player_masks),\n",
        "            mask=player_masks,\n",
        "            tracker_id=np.array(tracker_ids)\n",
        "        )\n",
        "\n",
        "    frames_history.append(frame)\n",
        "    detections_history.append(player_detections)\n",
        "\n",
        "    # Recognize numbers every 5 frames for efficiency\n",
        "    if index % 5 == 0:\n",
        "        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.4, iou_threshold=0.9)[0]\n",
        "        number_detections = sv.Detections.from_inference(result)\n",
        "        number_detections = number_detections[number_detections.class_id == NUMBER_CLASS_ID]\n",
        "        number_detections.mask = xyxy_to_mask(boxes=number_detections.xyxy, resolution_wh=(frame_w, frame_h))\n",
        "\n",
        "        number_crops = [sv.crop_image(frame, xyxy) for xyxy in sv.clip_boxes(sv.pad_boxes(xyxy=number_detections.xyxy, px=10), (frame_w, frame_h))]\n",
        "        numbers = [NUMBER_RECOGNITION_MODEL.predict(crop, NUMBER_RECOGNITION_MODEL_PROMPT)[0] for crop in number_crops]\n",
        "\n",
        "        # Match numbers to players using mask Intersection over Smaller area (IoS)\n",
        "        iou = sv.mask_iou_batch(player_masks, number_detections.mask, sv.OverlapMetric.IOS)\n",
        "        pairs = coords_above_threshold(iou, 0.9)\n",
        "        if len(pairs) > 0:\n",
        "            player_indices, number_indices = zip(*pairs)\n",
        "            matched_tracker_ids = [player_detections.tracker_id[i] for i in player_indices]\n",
        "            matched_numbers = [numbers[i] for i in number_indices]\n",
        "            number_validator.update(tracker_ids=matched_tracker_ids, values=matched_numbers)\n",
        "\n",
        "print(\"\\nâœ… Video processing complete.\")"
      ],
      "metadata": {
        "id": "ZjvCuxP4tr2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "e5003232-1b04-4bc2-a467-6f1d29c7f6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PropertyValidator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-58591817.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Initialize validators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnumber_validator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPropertyValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_consecutive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mteam_validator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPropertyValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_consecutive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PropertyValidator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "TARGET_VIDEO_PATH = HOME / f\"{SOURCE_VIDEO_PATH.stem}-result.mp4\"\n",
        "TARGET_VIDEO_COMPRESSED_PATH = HOME / f\"{SOURCE_VIDEO_PATH.stem}-result-compressed.mp4\"\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(str(SOURCE_VIDEO_PATH))\n",
        "\n",
        "# Set up annotators with team colors\n",
        "team_colors = sv.ColorPalette.from_hex([\n",
        "    TEAM_COLORS[TEAM_NAMES[0]],\n",
        "    TEAM_COLORS[TEAM_NAMES[1]]\n",
        "])\n",
        "team_mask_annotator = sv.MaskAnnotator(color=team_colors, opacity=0.5, color_lookup=sv.ColorLookup.INDEX)\n",
        "team_label_annotator = sv.RichLabelAnnotator(\n",
        "    font_path=f\"{HOME}/fonts/Staatliches-Regular.ttf\",\n",
        "    font_size=40, color=team_colors, text_color=sv.Color.WHITE,\n",
        "    text_position=sv.Position.BOTTOM_CENTER, text_offset=(0, 10),\n",
        "    color_lookup=sv.ColorLookup.INDEX\n",
        ")\n",
        "\n",
        "# Write the annotated frames to a new video file\n",
        "with sv.VideoSink(str(TARGET_VIDEO_PATH), video_info) as sink:\n",
        "    for frame, detections in tqdm(zip(frames_history, detections_history), desc=\"Generating final video\", total=len(frames_history)):\n",
        "        detections = detections[detections.area > 100]\n",
        "        if len(detections) == 0:\n",
        "            sink.write_frame(frame)\n",
        "            continue\n",
        "\n",
        "        # Get validated team and number for each player\n",
        "        teams = np.array(team_validator.get_validated(tracker_ids=detections.tracker_id)).astype(int)\n",
        "        numbers = np.array(number_validator.get_validated(tracker_ids=detections.tracker_id))\n",
        "\n",
        "        # Create labels with number and player name\n",
        "        labels = []\n",
        "        for number, team in zip(numbers, teams):\n",
        "            if number:\n",
        "                player_name = TEAM_ROSTERS[TEAM_NAMES[team]].get(number, \"\")\n",
        "                labels.append(f\"#{number} {player_name}\")\n",
        "            else:\n",
        "                labels.append(TEAM_NAMES[team])\n",
        "\n",
        "        # Annotate the frame\n",
        "        annotated_frame = frame.copy()\n",
        "        annotated_frame = team_mask_annotator.annotate(scene=annotated_frame, detections=detections, custom_color_lookup=teams)\n",
        "        annotated_frame = team_label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels, custom_color_lookup=teams)\n",
        "        sink.write_frame(annotated_frame)\n",
        "\n",
        "# Compress the video for easier viewing in Colab\n",
        "!ffmpeg -y -loglevel error -i {TARGET_VIDEO_PATH} -vcodec libx264 -crf 28 {TARGET_VIDEO_COMPRESSED_PATH}\n",
        "\n",
        "# Display the final result! ğŸ€\n",
        "Video(TARGET_VIDEO_COMPRESSED_PATH, embed=True, width=1080)"
      ],
      "metadata": {
        "id": "oJ2HQRWStr5Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "25aa2684-973b-4a7d-ec76-44f3ff68917a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'HOME' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2036198797.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTARGET_VIDEO_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHOME\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{SOURCE_VIDEO_PATH.stem}-result.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mTARGET_VIDEO_COMPRESSED_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHOME\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{SOURCE_VIDEO_PATH.stem}-result-compressed.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'HOME' is not defined"
          ]
        }
      ]
    }
  ]
}