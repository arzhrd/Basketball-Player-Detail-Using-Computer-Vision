{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arzhrd/Basketball-Player-Detail-Using-Computer-Vision/blob/main/Basketball_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiBSXEveueW-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics opencv-python-headless scikit-learn\n",
        "!pip install torch torchvision\n",
        "!pip install transformers pillow\n",
        "!pip install supervision"
      ],
      "metadata": {
        "id": "482eM5vPt4ou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a292fb-6db9-478d-d2c0-c0207c8a3801"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.222-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.222-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.222 ultralytics-thop-2.0.18\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Collecting supervision\n",
            "  Downloading supervision-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (1.16.2)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (6.0.3)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.12/dist-packages (from supervision) (11.3.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.67.1)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.12.0.88)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n",
            "Downloading supervision-0.26.1-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: supervision\n",
            "Successfully installed supervision-0.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "from ultralytics import YOLO\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import defaultdict, Counter\n",
        "import os\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML, display\n",
        "from base64 import b64encode\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pylx6PwYhG08",
        "outputId": "4fadcb8f-4f53-4614-a37d-7ae0f4b91dd2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload your basketball video\n",
        "print(\"Please upload your basketball video file...\")\n",
        "uploaded = files.upload()\n",
        "input_video_path = list(uploaded.keys())[0]\n",
        "print(f\"Video uploaded: {input_video_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "PzfFTB67hG6w",
        "outputId": "ebbd85b2-ade7-4fcb-8753-0af75acf0533"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your basketball video file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4675a436-2345-4c27-95a9-9d38a972666e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4675a436-2345-4c27-95a9-9d38a972666e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving video_1.mp4 to video_1.mp4\n",
            "Video uploaded: video_1.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_video(video_path):\n",
        "    \"\"\"Read video and return frames\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "def save_video(output_video_frames, output_video_path, fps=24):\n",
        "    \"\"\"Save frames as video\"\"\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps,\n",
        "                          (output_video_frames[0].shape[1], output_video_frames[0].shape[0]))\n",
        "    for frame in output_video_frames:\n",
        "        out.write(frame)\n",
        "    out.release()\n",
        "    print(f\"Video saved to: {output_video_path}\")\n",
        "\n",
        "def display_video(video_path):\n",
        "    \"\"\"Display video in Colab\"\"\"\n",
        "    mp4 = open(video_path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(f\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "PLkx3uIwhPhN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_center_of_bbox(bbox):\n",
        "    \"\"\"Get center point of bounding box\"\"\"\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    return int((x1 + x2) / 2), int((y1 + y2) / 2)\n",
        "\n",
        "def get_bbox_width(bbox):\n",
        "    \"\"\"Get width of bounding box\"\"\"\n",
        "    return bbox[2] - bbox[0]\n",
        "\n",
        "def measure_distance(p1, p2):\n",
        "    \"\"\"Measure Euclidean distance between two points\"\"\"\n",
        "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5\n",
        "\n",
        "def get_foot_position(bbox):\n",
        "    \"\"\"Get foot position (bottom center) of bounding box\"\"\"\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    return int((x1 + x2) / 2), int(y2)"
      ],
      "metadata": {
        "id": "AaslFkthhPjb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlayerTracker:\n",
        "    def __init__(self, model_path='yolov8x.pt'):\n",
        "        \"\"\"Initialize player tracker with YOLO model\"\"\"\n",
        "        self.model = YOLO(model_path)\n",
        "\n",
        "    def detect_frames(self, frames, read_from_stub=False, stub_path=None):\n",
        "        \"\"\"Detect players in frames\"\"\"\n",
        "        player_detections = []\n",
        "\n",
        "        if read_from_stub and stub_path is not None and os.path.exists(stub_path):\n",
        "            with open(stub_path, 'rb') as f:\n",
        "                player_detections = pickle.load(f)\n",
        "            return player_detections\n",
        "\n",
        "        for frame in frames:\n",
        "            player_dict = self.detect_frame(frame)\n",
        "            player_detections.append(player_dict)\n",
        "\n",
        "        if stub_path is not None:\n",
        "            with open(stub_path, 'wb') as f:\n",
        "                pickle.dump(player_detections, f)\n",
        "\n",
        "        return player_detections\n",
        "\n",
        "    def detect_frame(self, frame):\n",
        "        \"\"\"Detect players in a single frame\"\"\"\n",
        "        results = self.model.track(frame, persist=True)[0]\n",
        "        id_name_dict = results.names\n",
        "\n",
        "        player_dict = {}\n",
        "        for box in results.boxes:\n",
        "            track_id = int(box.id.tolist()[0]) if box.id is not None else -1\n",
        "            result = box.xyxy.tolist()[0]\n",
        "            object_cls_id = box.cls.tolist()[0]\n",
        "            object_cls_name = id_name_dict[object_cls_id]\n",
        "\n",
        "            if object_cls_name == \"person\":\n",
        "                player_dict[track_id] = result\n",
        "\n",
        "        return player_dict"
      ],
      "metadata": {
        "id": "0gv9KbnShPlV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BallTracker:\n",
        "    def __init__(self, model_path='yolov8x.pt'):\n",
        "        \"\"\"Initialize ball tracker with YOLO model\"\"\"\n",
        "        self.model = YOLO(model_path)\n",
        "\n",
        "    def interpolate_ball_positions(self, ball_positions):\n",
        "        \"\"\"Interpolate missing ball positions\"\"\"\n",
        "        ball_positions = [x.get(1, []) for x in ball_positions]\n",
        "        df_ball_positions = pd.DataFrame(ball_positions, columns=['x1', 'y1', 'x2', 'y2'])\n",
        "\n",
        "        # Interpolate missing values\n",
        "        df_ball_positions = df_ball_positions.interpolate()\n",
        "        df_ball_positions = df_ball_positions.bfill()\n",
        "\n",
        "        ball_positions = [{1: x} for x in df_ball_positions.to_numpy().tolist()]\n",
        "        return ball_positions\n",
        "\n",
        "    def detect_frames(self, frames, read_from_stub=False, stub_path=None):\n",
        "        \"\"\"Detect ball in frames\"\"\"\n",
        "        ball_detections = []\n",
        "\n",
        "        if read_from_stub and stub_path is not None and os.path.exists(stub_path):\n",
        "            with open(stub_path, 'rb') as f:\n",
        "                ball_detections = pickle.load(f)\n",
        "            return ball_detections\n",
        "\n",
        "        for frame in frames:\n",
        "            ball_dict = self.detect_frame(frame)\n",
        "            ball_detections.append(ball_dict)\n",
        "\n",
        "        if stub_path is not None:\n",
        "            with open(stub_path, 'wb') as f:\n",
        "                pickle.dump(ball_detections, f)\n",
        "\n",
        "        return ball_detections\n",
        "\n",
        "    def detect_frame(self, frame):\n",
        "        \"\"\"Detect ball in a single frame\"\"\"\n",
        "        results = self.model.predict(frame, conf=0.15)[0]\n",
        "        id_name_dict = results.names\n",
        "\n",
        "        ball_dict = {}\n",
        "        for box in results.boxes:\n",
        "            result = box.xyxy.tolist()[0]\n",
        "            object_cls_id = box.cls.tolist()[0]\n",
        "            object_cls_name = id_name_dict[object_cls_id]\n",
        "\n",
        "            if object_cls_name == \"sports ball\":\n",
        "                ball_dict[1] = result\n",
        "\n",
        "        return ball_dict"
      ],
      "metadata": {
        "id": "sUoz7DWchPnO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TeamAssigner:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize team assigner\"\"\"\n",
        "        self.team_colors = {}\n",
        "        self.player_team_dict = {}\n",
        "\n",
        "    def get_clustering_model(self, image):\n",
        "        \"\"\"Get KMeans clustering model for the image\"\"\"\n",
        "        # Reshape the image to 2D array\n",
        "        image_2d = image.reshape(-1, 3)\n",
        "\n",
        "        # Perform KMeans with 2 clusters\n",
        "        kmeans = KMeans(n_clusters=2, init=\"k-means++\", n_init=1)\n",
        "        kmeans.fit(image_2d)\n",
        "\n",
        "        return kmeans\n",
        "\n",
        "    def get_player_color(self, frame, bbox):\n",
        "        \"\"\"Get the dominant color of player's jersey\"\"\"\n",
        "        image = frame[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "\n",
        "        # Get the top half of the image (jersey area)\n",
        "        top_half_image = image[0:int(image.shape[0]/2), :]\n",
        "\n",
        "        # Get clustering model\n",
        "        kmeans = self.get_clustering_model(top_half_image)\n",
        "\n",
        "        # Get the cluster labels for each pixel\n",
        "        labels = kmeans.labels_\n",
        "\n",
        "        # Reshape the labels to the original image shape\n",
        "        clustered_image = labels.reshape(top_half_image.shape[0], top_half_image.shape[1])\n",
        "\n",
        "        # Get the player cluster (most common cluster in center)\n",
        "        corner_clusters = [clustered_image[0, 0], clustered_image[0, -1],\n",
        "                          clustered_image[-1, 0], clustered_image[-1, -1]]\n",
        "        non_player_cluster = max(set(corner_clusters), key=corner_clusters.count)\n",
        "        player_cluster = 1 - non_player_cluster\n",
        "\n",
        "        player_color = kmeans.cluster_centers_[player_cluster]\n",
        "\n",
        "        return player_color\n",
        "\n",
        "    def assign_team_color(self, frame, player_detections):\n",
        "        \"\"\"Assign team colors based on player jersey colors\"\"\"\n",
        "        player_colors = []\n",
        "        for _, player_bbox in player_detections.items():\n",
        "            bbox = player_bbox\n",
        "            player_color = self.get_player_color(frame, bbox)\n",
        "            player_colors.append(player_color)\n",
        "\n",
        "        kmeans = KMeans(n_clusters=2, init=\"k-means++\", n_init=10)\n",
        "        kmeans.fit(player_colors)\n",
        "\n",
        "        self.kmeans = kmeans\n",
        "\n",
        "        self.team_colors[1] = kmeans.cluster_centers_[0]\n",
        "        self.team_colors[2] = kmeans.cluster_centers_[1]\n",
        "\n",
        "    def get_player_team(self, frame, player_bbox, player_id):\n",
        "        \"\"\"Get which team a player belongs to\"\"\"\n",
        "        if player_id in self.player_team_dict:\n",
        "            return self.player_team_dict[player_id]\n",
        "\n",
        "        player_color = self.get_player_color(frame, player_bbox)\n",
        "\n",
        "        team_id = self.kmeans.predict(player_color.reshape(1, -1))[0]\n",
        "        team_id += 1\n",
        "\n",
        "        self.player_team_dict[player_id] = team_id\n",
        "\n",
        "        return team_id"
      ],
      "metadata": {
        "id": "axlRyT4FhPpn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BallPossessionAssigner:\n",
        "    def __init__(self):\n",
        "        self.max_player_ball_distance = 70\n",
        "\n",
        "    def assign_ball_to_player(self, players, ball_bbox):\n",
        "        \"\"\"Assign ball to the closest player\"\"\"\n",
        "        ball_position = get_center_of_bbox(ball_bbox)\n",
        "\n",
        "        minimum_distance = 99999\n",
        "        assigned_player = -1\n",
        "\n",
        "        for player_id, player_bbox in players.items():\n",
        "            player_position = get_foot_position(player_bbox)\n",
        "\n",
        "            distance = measure_distance(player_position, ball_position)\n",
        "\n",
        "            if distance < self.max_player_ball_distance:\n",
        "                if distance < minimum_distance:\n",
        "                    minimum_distance = distance\n",
        "                    assigned_player = player_id\n",
        "\n",
        "        return assigned_player"
      ],
      "metadata": {
        "id": "3p011_Hdifjn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_ellipse(frame, bbox, color, track_id=None):\n",
        "    \"\"\"Draw an ellipse at the bottom of bounding box\"\"\"\n",
        "    y2 = int(bbox[3])\n",
        "    x_center, _ = get_center_of_bbox(bbox)\n",
        "    width = get_bbox_width(bbox)\n",
        "\n",
        "    cv2.ellipse(\n",
        "        frame,\n",
        "        center=(x_center, y2),\n",
        "        axes=(int(width), int(0.35*width)),\n",
        "        angle=0.0,\n",
        "        startAngle=-45,\n",
        "        endAngle=235,\n",
        "        color=color,\n",
        "        thickness=2,\n",
        "        lineType=cv2.LINE_4\n",
        "    )\n",
        "\n",
        "    if track_id is not None:\n",
        "        rectangle_width = 40\n",
        "        rectangle_height = 20\n",
        "        x1_rect = x_center - rectangle_width // 2\n",
        "        x2_rect = x_center + rectangle_width // 2\n",
        "        y1_rect = (y2 - rectangle_height // 2) + 15\n",
        "        y2_rect = (y2 + rectangle_height // 2) + 15\n",
        "\n",
        "        cv2.rectangle(frame,\n",
        "                     (int(x1_rect), int(y1_rect)),\n",
        "                     (int(x2_rect), int(y2_rect)),\n",
        "                     color,\n",
        "                     cv2.FILLED)\n",
        "\n",
        "        x1_text = x1_rect + 12\n",
        "        y1_text = y1_rect + 15\n",
        "\n",
        "        cv2.putText(\n",
        "            frame,\n",
        "            f\"{track_id}\",\n",
        "            (int(x1_text), int(y1_text)),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.6,\n",
        "            (0, 0, 0),\n",
        "            2\n",
        "        )\n",
        "\n",
        "    return frame\n",
        "\n",
        "def draw_triangle(frame, bbox, color):\n",
        "    \"\"\"Draw a triangle above the bounding box (for ball)\"\"\"\n",
        "    y = int(bbox[1])\n",
        "    x, _ = get_center_of_bbox(bbox)\n",
        "\n",
        "    triangle_points = np.array([\n",
        "        [x, y],\n",
        "        [x-10, y-20],\n",
        "        [x+10, y-20],\n",
        "    ])\n",
        "    cv2.drawContours(frame, [triangle_points], 0, color, cv2.FILLED)\n",
        "    cv2.drawContours(frame, [triangle_points], 0, (0, 0, 0), 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "def draw_team_possession(frame, frame_num, team_possession):\n",
        "    \"\"\"Draw team possession stats on frame\"\"\"\n",
        "    overlay = frame.copy()\n",
        "    cv2.rectangle(overlay, (1350, 850), (1900, 970), (255, 255, 255), cv2.FILLED)\n",
        "    alpha = 0.4\n",
        "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
        "\n",
        "    team_possession_till_frame = team_possession[:frame_num+1]\n",
        "    team_1_frames = team_possession_till_frame[team_possession_till_frame == 1].shape[0]\n",
        "    team_2_frames = team_possession_till_frame[team_possession_till_frame == 2].shape[0]\n",
        "\n",
        "    total_frames = team_1_frames + team_2_frames\n",
        "    if total_frames > 0:\n",
        "        team_1_percent = team_1_frames / total_frames\n",
        "        team_2_percent = team_2_frames / total_frames\n",
        "    else:\n",
        "        team_1_percent = 0\n",
        "        team_2_percent = 0\n",
        "\n",
        "    cv2.putText(frame, f\"Team 1 Possession: {team_1_percent*100:.1f}%\",\n",
        "                (1400, 900), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 3)\n",
        "    cv2.putText(frame, f\"Team 2 Possession: {team_2_percent*100:.1f}%\",\n",
        "                (1400, 950), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 3)\n",
        "\n",
        "    return frame\n",
        "\n",
        "def draw_annotations(video_frames, tracks, team_possession):\n",
        "    \"\"\"Draw all annotations on video frames\"\"\"\n",
        "    output_video_frames = []\n",
        "    for frame_num, frame in enumerate(video_frames):\n",
        "        frame = frame.copy()\n",
        "\n",
        "        player_dict = tracks[\"players\"][frame_num]\n",
        "        ball_dict = tracks[\"ball\"][frame_num]\n",
        "\n",
        "        # Draw Players\n",
        "        for track_id, player_bbox in player_dict.items():\n",
        "            if isinstance(player_bbox, list):\n",
        "                color = (0, 0, 255)  # Default red\n",
        "                has_ball = False\n",
        "                actual_bbox = player_bbox\n",
        "            else:\n",
        "                color = player_bbox.get(\"team_color\", (0, 0, 255))\n",
        "                has_ball = player_bbox.get('has_ball', False)\n",
        "                actual_bbox = player_bbox.get('bbox', player_bbox)\n",
        "\n",
        "            frame = draw_ellipse(frame, actual_bbox, color, track_id)\n",
        "\n",
        "            if has_ball:\n",
        "                frame = draw_triangle(frame, actual_bbox, (0, 0, 255))\n",
        "\n",
        "        # Draw ball\n",
        "        for track_id, ball_bbox in ball_dict.items():\n",
        "            frame = draw_triangle(frame, ball_bbox, (0, 255, 0))\n",
        "\n",
        "        # Draw Team Possession\n",
        "        frame = draw_team_possession(frame, frame_num, team_possession)\n",
        "\n",
        "        output_video_frames.append(frame)\n",
        "\n",
        "    return output_video_frames"
      ],
      "metadata": {
        "id": "DRuRRbXghPsc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read video\n",
        "print(\"Reading video frames...\")\n",
        "video_frames = read_video(input_video_path)\n",
        "print(f\"Total frames: {len(video_frames)}\")\n",
        "\n",
        "# Initialize Trackers\n",
        "print(\"\\nInitializing trackers...\")\n",
        "player_tracker = PlayerTracker(model_path='yolov8x.pt')\n",
        "ball_tracker = BallTracker(model_path='yolov8x.pt')\n",
        "\n",
        "# Detect players and ball\n",
        "print(\"\\nDetecting players...\")\n",
        "player_detections = player_tracker.detect_frames(video_frames,\n",
        "                                                  read_from_stub=False,\n",
        "                                                  stub_path='player_detections.pkl')\n",
        "print(f\"Player detections completed: {len(player_detections)} frames\")\n",
        "\n",
        "print(\"\\nDetecting ball...\")\n",
        "ball_detections = ball_tracker.detect_frames(video_frames,\n",
        "                                             read_from_stub=False,\n",
        "                                             stub_path='ball_detections.pkl')\n",
        "\n",
        "# Interpolate ball positions\n",
        "try:\n",
        "    ball_detections = ball_tracker.interpolate_ball_positions(ball_detections)\n",
        "    print(\"Ball position interpolation completed\")\n",
        "except:\n",
        "    print(\"Ball interpolation skipped (requires pandas)\")\n",
        "\n",
        "# Assign players to teams\n",
        "print(\"\\nAssigning teams...\")\n",
        "team_assigner = TeamAssigner()\n",
        "team_assigner.assign_team_color(video_frames[0], player_detections[0])\n",
        "\n",
        "for frame_num, player_detection in enumerate(player_detections):\n",
        "    for player_id, bbox in player_detection.items():\n",
        "        team = team_assigner.get_player_team(video_frames[frame_num], bbox, player_id)\n",
        "\n",
        "        if isinstance(bbox, dict):\n",
        "            player_dict = bbox.copy()\n",
        "        else:\n",
        "            player_dict = {}\n",
        "\n",
        "        player_dict['team'] = team\n",
        "        player_dict['team_color'] = team_assigner.team_colors[team]\n",
        "        player_detections[frame_num][player_id] = player_dict\n",
        "\n",
        "# Assign ball possession\n",
        "print(\"\\nAssigning ball possession...\")\n",
        "ball_possession_assigner = BallPossessionAssigner()\n",
        "team_possession = []\n",
        "\n",
        "for frame_num, player_detection in enumerate(player_detections):\n",
        "    ball_bbox = ball_detections[frame_num].get(1, [])\n",
        "\n",
        "    player_bboxes = {}\n",
        "    for k, v in player_detection.items():\n",
        "        if isinstance(v, dict):\n",
        "            player_bboxes[k] = v.get('bbox', [v.get('x1', 0), v.get('y1', 0), v.get('x2', 0), v.get('y2', 0)])\n",
        "        else:\n",
        "            player_bboxes[k] = v\n",
        "\n",
        "    assigned_player = ball_possession_assigner.assign_ball_to_player(player_bboxes, ball_bbox)\n",
        "\n",
        "    if assigned_player != -1:\n",
        "        player_detections[frame_num][assigned_player]['has_ball'] = True\n",
        "        team = player_detections[frame_num][assigned_player]['team']\n",
        "        team_possession.append(team)\n",
        "    else:\n",
        "        team_possession.append(team_possession[-1] if team_possession else 0)\n",
        "\n",
        "team_possession = np.array(team_possession)\n",
        "\n",
        "# Prepare tracks dictionary\n",
        "tracks = {\n",
        "    \"players\": [{k: v if not isinstance(v, dict) else [v.get('bbox', [0,0,0,0])]\n",
        "                 for k, v in frame.items()} for frame in player_detections],\n",
        "    \"ball\": ball_detections\n",
        "}\n",
        "\n",
        "# Fix the tracks format\n",
        "for frame_num in range(len(tracks[\"players\"])):\n",
        "    for player_id in tracks[\"players\"][frame_num]:\n",
        "        bbox_data = tracks[\"players\"][frame_num][player_id]\n",
        "        if isinstance(bbox_data, list) and len(bbox_data) == 1:\n",
        "            tracks[\"players\"][frame_num][player_id] = bbox_data[0]\n",
        "\n",
        "print(\"\\nProcessing complete! Preparing output video...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6xWqCaVimYX",
        "outputId": "f497bb58-2db9-4da3-ee9f-17ea016b2685"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading video frames...\n",
            "Total frames: 117\n",
            "\n",
            "Initializing trackers...\n",
            "\n",
            "Detecting players...\n",
            "\n",
            "0: 384x640 10 persons, 1 sports ball, 63.5ms\n",
            "Speed: 1.9ms preprocess, 63.5ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 sports ball, 49.8ms\n",
            "Speed: 2.3ms preprocess, 49.8ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 sports ball, 33.6ms\n",
            "Speed: 2.0ms preprocess, 33.6ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 33.5ms\n",
            "Speed: 2.0ms preprocess, 33.5ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 31.1ms\n",
            "Speed: 2.1ms preprocess, 31.1ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 30.8ms\n",
            "Speed: 3.0ms preprocess, 30.8ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 31.2ms\n",
            "Speed: 1.9ms preprocess, 31.2ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 29.4ms\n",
            "Speed: 2.6ms preprocess, 29.4ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 30.4ms\n",
            "Speed: 2.1ms preprocess, 30.4ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 30.1ms\n",
            "Speed: 2.0ms preprocess, 30.1ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 29.8ms\n",
            "Speed: 2.2ms preprocess, 29.8ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 29.3ms\n",
            "Speed: 3.0ms preprocess, 29.3ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 30.4ms\n",
            "Speed: 2.0ms preprocess, 30.4ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 29.3ms\n",
            "Speed: 1.6ms preprocess, 29.3ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 30.4ms\n",
            "Speed: 2.2ms preprocess, 30.4ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 29.9ms\n",
            "Speed: 2.4ms preprocess, 29.9ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 29.5ms\n",
            "Speed: 1.9ms preprocess, 29.5ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 30.4ms\n",
            "Speed: 2.3ms preprocess, 30.4ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 29.9ms\n",
            "Speed: 2.1ms preprocess, 29.9ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 30.3ms\n",
            "Speed: 2.1ms preprocess, 30.3ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 30.0ms\n",
            "Speed: 2.0ms preprocess, 30.0ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 29.4ms\n",
            "Speed: 2.0ms preprocess, 29.4ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 30.6ms\n",
            "Speed: 2.9ms preprocess, 30.6ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 29.6ms\n",
            "Speed: 2.2ms preprocess, 29.6ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 29.9ms\n",
            "Speed: 2.0ms preprocess, 29.9ms inference, 19.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 29.1ms\n",
            "Speed: 3.1ms preprocess, 29.1ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 30.2ms\n",
            "Speed: 2.0ms preprocess, 30.2ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 30.1ms\n",
            "Speed: 2.3ms preprocess, 30.1ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 29.5ms\n",
            "Speed: 2.9ms preprocess, 29.5ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 stop sign, 30.1ms\n",
            "Speed: 2.1ms preprocess, 30.1ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 stop sign, 29.9ms\n",
            "Speed: 2.3ms preprocess, 29.9ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 stop sign, 29.5ms\n",
            "Speed: 2.6ms preprocess, 29.5ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 stop sign, 30.1ms\n",
            "Speed: 2.6ms preprocess, 30.1ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.1ms\n",
            "Speed: 2.2ms preprocess, 30.1ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 31.4ms\n",
            "Speed: 2.2ms preprocess, 31.4ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 stop sign, 31.3ms\n",
            "Speed: 2.3ms preprocess, 31.3ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 stop sign, 31.4ms\n",
            "Speed: 1.9ms preprocess, 31.4ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 29.6ms\n",
            "Speed: 2.4ms preprocess, 29.6ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 stop sign, 29.3ms\n",
            "Speed: 2.4ms preprocess, 29.3ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 29.7ms\n",
            "Speed: 2.6ms preprocess, 29.7ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.1ms\n",
            "Speed: 2.3ms preprocess, 30.1ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.2ms\n",
            "Speed: 2.0ms preprocess, 30.2ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 29.5ms\n",
            "Speed: 1.8ms preprocess, 29.5ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 29.2ms\n",
            "Speed: 2.2ms preprocess, 29.2ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 28.9ms\n",
            "Speed: 2.3ms preprocess, 28.9ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 29.0ms\n",
            "Speed: 2.6ms preprocess, 29.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 29.2ms\n",
            "Speed: 1.9ms preprocess, 29.2ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 30.2ms\n",
            "Speed: 2.4ms preprocess, 30.2ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 30.3ms\n",
            "Speed: 2.6ms preprocess, 30.3ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 29.7ms\n",
            "Speed: 3.5ms preprocess, 29.7ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 29.2ms\n",
            "Speed: 1.6ms preprocess, 29.2ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 30.3ms\n",
            "Speed: 2.3ms preprocess, 30.3ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 29.9ms\n",
            "Speed: 2.2ms preprocess, 29.9ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 30.6ms\n",
            "Speed: 2.3ms preprocess, 30.6ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 30.2ms\n",
            "Speed: 2.1ms preprocess, 30.2ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 30.1ms\n",
            "Speed: 2.3ms preprocess, 30.1ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 30.6ms\n",
            "Speed: 2.5ms preprocess, 30.6ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 stop sign, 30.6ms\n",
            "Speed: 2.1ms preprocess, 30.6ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 29.0ms\n",
            "Speed: 2.3ms preprocess, 29.0ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 29.5ms\n",
            "Speed: 2.6ms preprocess, 29.5ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.1ms\n",
            "Speed: 3.5ms preprocess, 30.1ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.0ms\n",
            "Speed: 2.5ms preprocess, 30.0ms inference, 19.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.0ms\n",
            "Speed: 2.3ms preprocess, 30.0ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 29.7ms\n",
            "Speed: 2.4ms preprocess, 29.7ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 29.6ms\n",
            "Speed: 1.7ms preprocess, 29.6ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 28.9ms\n",
            "Speed: 2.5ms preprocess, 28.9ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.1ms\n",
            "Speed: 2.2ms preprocess, 30.1ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 30.3ms\n",
            "Speed: 2.3ms preprocess, 30.3ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 30.1ms\n",
            "Speed: 2.4ms preprocess, 30.1ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 stop sign, 30.4ms\n",
            "Speed: 2.2ms preprocess, 30.4ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 stop sign, 30.7ms\n",
            "Speed: 2.6ms preprocess, 30.7ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 stop sign, 29.4ms\n",
            "Speed: 2.5ms preprocess, 29.4ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 stop sign, 30.3ms\n",
            "Speed: 2.0ms preprocess, 30.3ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 30.4ms\n",
            "Speed: 1.9ms preprocess, 30.4ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 29.6ms\n",
            "Speed: 2.4ms preprocess, 29.6ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 stop sign, 29.3ms\n",
            "Speed: 2.2ms preprocess, 29.3ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 stop sign, 30.4ms\n",
            "Speed: 2.2ms preprocess, 30.4ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 29.3ms\n",
            "Speed: 1.9ms preprocess, 29.3ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 stop sign, 30.3ms\n",
            "Speed: 5.0ms preprocess, 30.3ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 29.6ms\n",
            "Speed: 2.4ms preprocess, 29.6ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.2ms\n",
            "Speed: 2.1ms preprocess, 30.2ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 29.2ms\n",
            "Speed: 2.2ms preprocess, 29.2ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.6ms\n",
            "Speed: 2.5ms preprocess, 30.6ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.1ms\n",
            "Speed: 2.1ms preprocess, 30.1ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 29.3ms\n",
            "Speed: 2.9ms preprocess, 29.3ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 30.4ms\n",
            "Speed: 2.3ms preprocess, 30.4ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 29.8ms\n",
            "Speed: 2.1ms preprocess, 29.8ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 stop sign, 30.6ms\n",
            "Speed: 2.6ms preprocess, 30.6ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 stop sign, 30.7ms\n",
            "Speed: 2.1ms preprocess, 30.7ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 stop sign, 30.3ms\n",
            "Speed: 2.1ms preprocess, 30.3ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 stop sign, 29.8ms\n",
            "Speed: 2.2ms preprocess, 29.8ms inference, 52.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 stop sign, 31.2ms\n",
            "Speed: 5.2ms preprocess, 31.2ms inference, 25.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 stop sign, 28.6ms\n",
            "Speed: 2.8ms preprocess, 28.6ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 stop sign, 28.7ms\n",
            "Speed: 2.0ms preprocess, 28.7ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 stop sign, 30.5ms\n",
            "Speed: 3.2ms preprocess, 30.5ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 stop sign, 30.1ms\n",
            "Speed: 2.1ms preprocess, 30.1ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 stop sign, 30.6ms\n",
            "Speed: 5.7ms preprocess, 30.6ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 30.6ms\n",
            "Speed: 2.5ms preprocess, 30.6ms inference, 29.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 30.9ms\n",
            "Speed: 2.6ms preprocess, 30.9ms inference, 34.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 30.7ms\n",
            "Speed: 3.1ms preprocess, 30.7ms inference, 24.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 43.1ms\n",
            "Speed: 2.3ms preprocess, 43.1ms inference, 24.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 30.8ms\n",
            "Speed: 4.3ms preprocess, 30.8ms inference, 32.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 30.6ms\n",
            "Speed: 2.2ms preprocess, 30.6ms inference, 21.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 54.2ms\n",
            "Speed: 4.0ms preprocess, 54.2ms inference, 48.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 41.3ms\n",
            "Speed: 7.2ms preprocess, 41.3ms inference, 50.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 30.9ms\n",
            "Speed: 5.4ms preprocess, 30.9ms inference, 32.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 30.7ms\n",
            "Speed: 2.3ms preprocess, 30.7ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 31.0ms\n",
            "Speed: 2.3ms preprocess, 31.0ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 30.9ms\n",
            "Speed: 2.9ms preprocess, 30.9ms inference, 20.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 35.8ms\n",
            "Speed: 3.4ms preprocess, 35.8ms inference, 19.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 35.4ms\n",
            "Speed: 1.9ms preprocess, 35.4ms inference, 20.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 35.2ms\n",
            "Speed: 2.0ms preprocess, 35.2ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 35.7ms\n",
            "Speed: 2.0ms preprocess, 35.7ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 35.9ms\n",
            "Speed: 2.3ms preprocess, 35.9ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 37.3ms\n",
            "Speed: 2.2ms preprocess, 37.3ms inference, 24.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 36.0ms\n",
            "Speed: 2.7ms preprocess, 36.0ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 36.0ms\n",
            "Speed: 3.2ms preprocess, 36.0ms inference, 22.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Player detections completed: 117 frames\n",
            "\n",
            "Detecting ball...\n",
            "\n",
            "0: 384x640 14 persons, 1 sports ball, 51.9ms\n",
            "Speed: 1.7ms preprocess, 51.9ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 sports balls, 2 chairs, 37.8ms\n",
            "Speed: 2.2ms preprocess, 37.8ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 sports ball, 31.3ms\n",
            "Speed: 3.0ms preprocess, 31.3ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 sports ball, 32.3ms\n",
            "Speed: 2.6ms preprocess, 32.3ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 tennis racket, 33.4ms\n",
            "Speed: 2.1ms preprocess, 33.4ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 tennis racket, 2 chairs, 33.0ms\n",
            "Speed: 2.0ms preprocess, 33.0ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 sports balls, 1 baseball glove, 2 chairs, 32.6ms\n",
            "Speed: 1.9ms preprocess, 32.6ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 1 sports ball, 1 chair, 32.6ms\n",
            "Speed: 1.9ms preprocess, 32.6ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 baseball glove, 2 chairs, 32.3ms\n",
            "Speed: 2.1ms preprocess, 32.3ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 baseball glove, 32.7ms\n",
            "Speed: 2.0ms preprocess, 32.7ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 32.9ms\n",
            "Speed: 2.2ms preprocess, 32.9ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 32.8ms\n",
            "Speed: 2.1ms preprocess, 32.8ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 33.0ms\n",
            "Speed: 2.1ms preprocess, 33.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 stop sign, 1 chair, 34.2ms\n",
            "Speed: 2.1ms preprocess, 34.2ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 32.8ms\n",
            "Speed: 2.5ms preprocess, 32.8ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 skateboard, 33.3ms\n",
            "Speed: 1.9ms preprocess, 33.3ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 skateboard, 32.8ms\n",
            "Speed: 3.7ms preprocess, 32.8ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 skateboards, 1 chair, 32.7ms\n",
            "Speed: 1.9ms preprocess, 32.7ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 32.6ms\n",
            "Speed: 2.1ms preprocess, 32.6ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 33.0ms\n",
            "Speed: 1.5ms preprocess, 33.0ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 35.0ms\n",
            "Speed: 1.9ms preprocess, 35.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 32.8ms\n",
            "Speed: 1.8ms preprocess, 32.8ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 baseball glove, 33.3ms\n",
            "Speed: 1.8ms preprocess, 33.3ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 baseball glove, 1 chair, 32.8ms\n",
            "Speed: 2.1ms preprocess, 32.8ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 32.3ms\n",
            "Speed: 2.0ms preprocess, 32.3ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 33.2ms\n",
            "Speed: 2.5ms preprocess, 33.2ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 stop sign, 32.7ms\n",
            "Speed: 1.6ms preprocess, 32.7ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 1 tennis racket, 33.7ms\n",
            "Speed: 2.1ms preprocess, 33.7ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 32.5ms\n",
            "Speed: 2.7ms preprocess, 32.5ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 33.2ms\n",
            "Speed: 1.5ms preprocess, 33.2ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 32.5ms\n",
            "Speed: 2.0ms preprocess, 32.5ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 33.0ms\n",
            "Speed: 1.8ms preprocess, 33.0ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 34.0ms\n",
            "Speed: 2.8ms preprocess, 34.0ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 33.0ms\n",
            "Speed: 2.4ms preprocess, 33.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 stop sign, 1 tennis racket, 33.9ms\n",
            "Speed: 2.2ms preprocess, 33.9ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 stop sign, 33.1ms\n",
            "Speed: 2.0ms preprocess, 33.1ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 stop sign, 33.3ms\n",
            "Speed: 2.0ms preprocess, 33.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 1 sports ball, 1 baseball glove, 35.4ms\n",
            "Speed: 1.9ms preprocess, 35.4ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 1 sports ball, 1 baseball glove, 32.9ms\n",
            "Speed: 2.1ms preprocess, 32.9ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 3 sports balls, 1 chair, 32.0ms\n",
            "Speed: 2.1ms preprocess, 32.0ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 32.3ms\n",
            "Speed: 2.0ms preprocess, 32.3ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 stop sign, 1 baseball glove, 33.1ms\n",
            "Speed: 2.5ms preprocess, 33.1ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 32.9ms\n",
            "Speed: 2.7ms preprocess, 32.9ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 1 sports ball, 32.7ms\n",
            "Speed: 2.9ms preprocess, 32.7ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 baseball glove, 32.7ms\n",
            "Speed: 2.3ms preprocess, 32.7ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 baseball glove, 32.7ms\n",
            "Speed: 2.1ms preprocess, 32.7ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 1 baseball glove, 34.3ms\n",
            "Speed: 2.1ms preprocess, 34.3ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 baseball glove, 32.7ms\n",
            "Speed: 2.0ms preprocess, 32.7ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 1 tennis racket, 32.6ms\n",
            "Speed: 2.5ms preprocess, 32.6ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 1 baseball glove, 33.0ms\n",
            "Speed: 2.1ms preprocess, 33.0ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 baseball glove, 32.5ms\n",
            "Speed: 2.1ms preprocess, 32.5ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 baseball glove, 32.5ms\n",
            "Speed: 2.1ms preprocess, 32.5ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 sports ball, 32.3ms\n",
            "Speed: 1.9ms preprocess, 32.3ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 sports ball, 32.8ms\n",
            "Speed: 2.2ms preprocess, 32.8ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 sports ball, 33.4ms\n",
            "Speed: 2.3ms preprocess, 33.4ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 1 sports ball, 1 tennis racket, 33.6ms\n",
            "Speed: 2.2ms preprocess, 33.6ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 stop sign, 1 sports ball, 32.3ms\n",
            "Speed: 1.7ms preprocess, 32.3ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 1 sports ball, 1 tennis racket, 32.9ms\n",
            "Speed: 1.9ms preprocess, 32.9ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 1 baseball glove, 32.8ms\n",
            "Speed: 1.8ms preprocess, 32.8ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 1 baseball glove, 33.7ms\n",
            "Speed: 1.9ms preprocess, 33.7ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 1 backpack, 1 baseball glove, 32.9ms\n",
            "Speed: 1.5ms preprocess, 32.9ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 1 baseball glove, 33.0ms\n",
            "Speed: 2.0ms preprocess, 33.0ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 32.7ms\n",
            "Speed: 2.2ms preprocess, 32.7ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 stop sign, 33.2ms\n",
            "Speed: 1.8ms preprocess, 33.2ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 33.7ms\n",
            "Speed: 1.8ms preprocess, 33.7ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 33.3ms\n",
            "Speed: 1.9ms preprocess, 33.3ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 stop sign, 1 surfboard, 32.5ms\n",
            "Speed: 2.0ms preprocess, 32.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 1 tennis racket, 33.5ms\n",
            "Speed: 1.6ms preprocess, 33.5ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 33.4ms\n",
            "Speed: 1.6ms preprocess, 33.4ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 baseball glove, 1 tennis racket, 32.7ms\n",
            "Speed: 1.8ms preprocess, 32.7ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 33.4ms\n",
            "Speed: 2.0ms preprocess, 33.4ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 tennis racket, 32.7ms\n",
            "Speed: 1.9ms preprocess, 32.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 stop sign, 1 tennis racket, 33.5ms\n",
            "Speed: 2.7ms preprocess, 33.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 2 tennis rackets, 33.0ms\n",
            "Speed: 2.3ms preprocess, 33.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 stop sign, 1 tennis racket, 32.9ms\n",
            "Speed: 2.5ms preprocess, 32.9ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 stop sign, 33.9ms\n",
            "Speed: 2.2ms preprocess, 33.9ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 sports ball, 33.0ms\n",
            "Speed: 2.0ms preprocess, 33.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 33.1ms\n",
            "Speed: 2.0ms preprocess, 33.1ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 32.6ms\n",
            "Speed: 2.0ms preprocess, 32.6ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 1 tennis racket, 32.9ms\n",
            "Speed: 2.2ms preprocess, 32.9ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 33.1ms\n",
            "Speed: 2.0ms preprocess, 33.1ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 stop sign, 1 umbrella, 32.8ms\n",
            "Speed: 2.1ms preprocess, 32.8ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 1 tennis racket, 34.8ms\n",
            "Speed: 1.6ms preprocess, 34.8ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 1 tennis racket, 33.0ms\n",
            "Speed: 2.2ms preprocess, 33.0ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 1 tennis racket, 32.9ms\n",
            "Speed: 2.3ms preprocess, 32.9ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 stop sign, 1 tennis racket, 31.7ms\n",
            "Speed: 1.6ms preprocess, 31.7ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 stop sign, 32.8ms\n",
            "Speed: 2.1ms preprocess, 32.8ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 stop sign, 4 tennis rackets, 32.7ms\n",
            "Speed: 2.0ms preprocess, 32.7ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 stop sign, 2 tennis rackets, 32.9ms\n",
            "Speed: 2.1ms preprocess, 32.9ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 stop sign, 33.2ms\n",
            "Speed: 2.1ms preprocess, 33.2ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 32.9ms\n",
            "Speed: 1.9ms preprocess, 32.9ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 32.9ms\n",
            "Speed: 1.9ms preprocess, 32.9ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 stop sign, 2 tennis rackets, 34.5ms\n",
            "Speed: 2.0ms preprocess, 34.5ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 stop sign, 1 baseball bat, 32.4ms\n",
            "Speed: 2.7ms preprocess, 32.4ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 stop sign, 1 tennis racket, 32.8ms\n",
            "Speed: 2.1ms preprocess, 32.8ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 stop sign, 31.8ms\n",
            "Speed: 2.2ms preprocess, 31.8ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 stop sign, 32.4ms\n",
            "Speed: 2.3ms preprocess, 32.4ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 2 chairs, 1 tv, 32.7ms\n",
            "Speed: 3.0ms preprocess, 32.7ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 2 tennis rackets, 3 chairs, 1 clock, 32.3ms\n",
            "Speed: 2.6ms preprocess, 32.3ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 chair, 31.1ms\n",
            "Speed: 2.6ms preprocess, 31.1ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 32.7ms\n",
            "Speed: 1.8ms preprocess, 32.7ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 skateboard, 1 chair, 34.7ms\n",
            "Speed: 2.2ms preprocess, 34.7ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 skis, 1 chair, 32.3ms\n",
            "Speed: 2.0ms preprocess, 32.3ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 tennis racket, 1 chair, 32.8ms\n",
            "Speed: 2.1ms preprocess, 32.8ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 skis, 32.1ms\n",
            "Speed: 2.8ms preprocess, 32.1ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 skis, 34.4ms\n",
            "Speed: 2.8ms preprocess, 34.4ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 skis, 33.3ms\n",
            "Speed: 2.2ms preprocess, 33.3ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 chair, 32.8ms\n",
            "Speed: 2.6ms preprocess, 32.8ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 skis, 33.0ms\n",
            "Speed: 2.5ms preprocess, 33.0ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 33.9ms\n",
            "Speed: 2.6ms preprocess, 33.9ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 32.7ms\n",
            "Speed: 2.1ms preprocess, 32.7ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 tennis racket, 33.3ms\n",
            "Speed: 2.8ms preprocess, 33.3ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 tennis racket, 33.0ms\n",
            "Speed: 2.2ms preprocess, 33.0ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 34.0ms\n",
            "Speed: 2.2ms preprocess, 34.0ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 chair, 33.2ms\n",
            "Speed: 2.2ms preprocess, 33.2ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 sports ball, 32.2ms\n",
            "Speed: 2.3ms preprocess, 32.2ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 32.8ms\n",
            "Speed: 1.5ms preprocess, 32.8ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Ball position interpolation completed\n",
            "\n",
            "Assigning teams...\n",
            "\n",
            "Assigning ball possession...\n",
            "\n",
            "Processing complete! Preparing output video...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw annotations on frames\n",
        "print(\"Drawing annotations...\")\n",
        "output_video_frames = draw_annotations(video_frames, tracks, team_possession)\n",
        "\n",
        "# Save output video\n",
        "output_path = 'output_basketball_analysis.mp4'\n",
        "save_video(output_video_frames, output_path, fps=24)\n",
        "\n",
        "print(f\"\\n✅ Analysis complete!\")\n",
        "print(f\"Output saved to: {output_path}\")\n",
        "\n",
        "# Display the output video\n",
        "print(\"\\nDisplaying output video...\")\n",
        "display(display_video(output_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "mCjhWnqDimcq",
        "outputId": "1dadd925-4e7a-439a-fbf3-e6824a6b11c5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drawing annotations...\n",
            "Video saved to: output_basketball_analysis.mp4\n",
            "\n",
            "✅ Analysis complete!\n",
            "Output saved to: output_basketball_analysis.mp4\n",
            "\n",
            "Displaying output video...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VMRFOM0FimeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oFwcpIL0imhK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPnqCJoj/QOgg1fucnXnEhU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}