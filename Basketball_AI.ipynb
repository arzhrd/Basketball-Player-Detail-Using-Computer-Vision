{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvz5PQZt/4QjrkiOmsny9f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arzhrd/Basketball-Player-Detail-Using-Computer-Vision/blob/main/Basketball_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Configure API Keys and check for GPU\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# Load API keys from Colab secrets\n",
        "try:\n",
        "    os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "    os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get(\"ROBOFLOW_API_KEY\")\n",
        "    print(\"API keys loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"Could not load API keys. Please set them up in Colab Secrets (üîë).\")\n",
        "    print(\"Required secrets: 'HF_TOKEN' and 'ROBOFLOW_API_KEY'\")\n",
        "\n",
        "# Check for GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Set home directory\n",
        "HOME = Path.cwd()\n",
        "print(\"HOME:\", HOME)\n",
        "\n",
        "# Set ONNX provider to use GPU\n",
        "os.environ[\"ONNXRUNTIME_EXECUTION_PROVIDERS\"] = \"[CUDAExecutionProvider]\"\n",
        "\n",
        "# 2. Install SAM2 (Segment Anything Model 2) for tracking\n",
        "!git clone https://github.com/Gy920/segment-anything-2-real-time.git\n",
        "%cd {HOME}/segment-anything-2-real-time\n",
        "!pip install -e . -q\n",
        "!python setup.py build_ext --inplace\n",
        "!(cd checkpoints && bash download_ckpts.sh)\n",
        "%cd {HOME}\n",
        "\n",
        "# 3. Install all other required Python packages\n",
        "!pip install -q gdown inference-gpu supervision transformers num2words\n",
        "!pip install -q git+https://github.com/roboflow/sports.git@feat/basketball\n",
        "!pip install -q flash-attn --no-build-isolation\n",
        "\n",
        "print(\"\\n‚úÖ All installations are complete.\")"
      ],
      "metadata": {
        "id": "T5WDXGLphaGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Download sample videos and fonts\n",
        "SOURCE_VIDEO_DIRECTORY = HOME / \"source\"\n",
        "!gdown -q https://drive.google.com/drive/folders/1eDJYqQ77Fytz15tKGdJCMeYSgmoQ-2-H -O {SOURCE_VIDEO_DIRECTORY} --folder\n",
        "!gdown -q https://drive.google.com/drive/folders/1RBjpI5Xleb58lujeusxH0W5zYMMA4ytO -O {HOME / \"fonts\"} --folder\n",
        "print(\"Sample videos and fonts downloaded.\")\n",
        "\n",
        "# 2. Define the source video path you want to process\n",
        "# You can change the filename to process a different clip from the `source` directory\n",
        "SOURCE_VIDEO_PATH = SOURCE_VIDEO_DIRECTORY / \"boston-celtics-new-york-knicks-game-1-q1-04.28-04.20.mp4\"\n",
        "\n",
        "# 3. Define Team Rosters and Colors\n",
        "TEAM_ROSTERS = {\n",
        "  \"New York Knicks\": {\n",
        "    \"55\": \"Hukporti\", \"1\": \"Payne\", \"0\": \"Wright\", \"11\": \"Brunson\", \"3\": \"Hart\",\n",
        "    \"32\": \"Towns\", \"44\": \"Shamet\", \"25\": \"Bridges\", \"2\": \"McBride\",\n",
        "    \"23\": \"Robinson\", \"8\": \"Anunoby\", \"4\": \"Dadiet\", \"5\": \"Achiuwa\", \"13\": \"Kolek\"\n",
        "  },\n",
        "  \"Boston Celtics\": {\n",
        "    \"42\": \"Horford\", \"55\": \"Scheierman\", \"9\": \"White\", \"20\": \"Davison\",\n",
        "    \"7\": \"Brown\", \"0\": \"Tatum\", \"27\": \"Walsh\", \"4\": \"Holiday\", \"8\": \"Porzingis\",\n",
        "    \"40\": \"Kornet\", \"88\": \"Queta\", \"11\": \"Pritchard\", \"30\": \"Hauser\",\n",
        "    \"12\": \"Craig\", \"26\": \"Tillman\"\n",
        "  }\n",
        "}\n",
        "\n",
        "TEAM_COLORS = {\n",
        "    \"New York Knicks\": \"#006BB6\",\n",
        "    \"Boston Celtics\": \"#007A33\"\n",
        "}"
      ],
      "metadata": {
        "id": "0GRLc11mhaue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "from inference import get_model\n",
        "from sam2.build_sam import build_sam2_camera_predictor\n",
        "import torch\n",
        "\n",
        "# 1. Load Player and Number Detection Model (RF-DETR)\n",
        "PLAYER_DETECTION_MODEL_ID = \"basketball-player-detection-3-ycjdo/4\"\n",
        "PLAYER_DETECTION_MODEL = get_model(model_id=PLAYER_DETECTION_MODEL_ID)\n",
        "\n",
        "# 2. Load Player Tracking Model (SAM2.1)\n",
        "%cd {HOME}/segment-anything-2-real-time\n",
        "SAM2_CHECKPOINT = \"checkpoints/sam2.1_hiera_large.pt\"\n",
        "SAM2_CONFIG = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "sam_predictor = build_sam2_camera_predictor(SAM2_CONFIG, SAM2_CHECKPOINT)\n",
        "%cd {HOME}\n",
        "\n",
        "# 3. Load Jersey Number Recognition Model (SmolVLM2)\n",
        "NUMBER_RECOGNITION_MODEL_ID = \"basketball-jersey-numbers-ocr/3\"\n",
        "NUMBER_RECOGNITION_MODEL = get_model(model_id=NUMBER_RECOGNITION_MODEL_ID)\n",
        "NUMBER_RECOGNITION_MODEL_PROMPT = \"Read the number.\"\n",
        "\n",
        "print(\"\\n‚úÖ All models loaded successfully.\")"
      ],
      "metadata": {
        "id": "YvQFQFVMh1fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "from sports.common.team import TeamClassifier\n",
        "\n",
        "# Class IDs for different player-related detections\n",
        "PLAYER_CLASS_IDS = [3, 4, 5, 6, 7]\n",
        "\n",
        "def shrink_boxes(xyxy: np.ndarray, scale: float) -> np.ndarray:\n",
        "    \"\"\"Shrinks bounding boxes to focus on the jersey.\"\"\"\n",
        "    x1, y1, x2, y2 = xyxy[:, 0], xyxy[:, 1], xyxy[:, 2], xyxy[:, 3]\n",
        "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "    w, h = (x2 - x1) * scale, (y2 - y1) * scale\n",
        "    new_x1, new_y1 = cx - w / 2, cy - h / 2\n",
        "    new_x2, new_y2 = cx + w / 2, cy + h / 2\n",
        "    return np.stack([new_x1, new_y1, new_x2, new_y2], axis=1)\n",
        "\n",
        "# 1. Collect player crops from all videos to build a training set\n",
        "crops = []\n",
        "for video_path in sv.list_files_with_extensions(SOURCE_VIDEO_DIRECTORY, extensions=[\"mp4\"]):\n",
        "    frame_generator = sv.get_video_frames_generator(source_path=str(video_path), stride=30)\n",
        "    for frame in tqdm(frame_generator, desc=f\"Processing {video_path.name}\"):\n",
        "        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.4, iou_threshold=0.9, class_agnostic_nms=True)[0]\n",
        "        detections = sv.Detections.from_inference(result)\n",
        "        detections = detections[np.isin(detections.class_id, PLAYER_CLASS_IDS)]\n",
        "        boxes = shrink_boxes(xyxy=detections.xyxy, scale=0.4)\n",
        "        for box in boxes:\n",
        "            crops.append(sv.crop_image(frame, box))\n",
        "\n",
        "# 2. Train the team classifier and predict teams for the collected crops\n",
        "team_classifier = TeamClassifier(device=\"cuda\")\n",
        "team_classifier.fit(crops)\n",
        "teams = team_classifier.predict(crops)\n",
        "\n",
        "# 3. Display the results of clustering for manual verification\n",
        "team_0 = [crop for crop, team in zip(crops, teams) if team == 0]\n",
        "team_1 = [crop for crop, team in zip(crops, teams) if team == 1]\n",
        "\n",
        "print(\"--- CLUSTER 0 ---\")\n",
        "sv.plot_images_grid(images=team_0[:20], grid_size=(2, 10), size=(10, 2))\n",
        "print(\"\\n--- CLUSTER 1 ---\")\n",
        "sv.plot_images_grid(images=team_1[:20], grid_size=(2, 10), size=(10, 2))"
      ],
      "metadata": {
        "id": "bFqO0BPN6cw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. MANUALLY ASSIGN TEAM NAMES BASED ON THE GRIDS ABOVE\n",
        "# Look at the images for Cluster 0 and Cluster 1 and assign the correct team name.\n",
        "# Uncomment the correct dictionary.\n",
        "\n",
        "TEAM_NAMES = {\n",
        "    0: \"New York Knicks\",\n",
        "    1: \"Boston Celtics\",\n",
        "}\n",
        "\n",
        "# TEAM_NAMES = {\n",
        "#     0: \"Boston Celtics\",\n",
        "#     1: \"New York Knicks\",\n",
        "# }\n",
        "\n",
        "print(\"Team names assigned:\")\n",
        "print(f\"Cluster 0 -> {TEAM_NAMES[0]}\")\n",
        "print(f\"Cluster 1 -> {TEAM_NAMES[1]}\")"
      ],
      "metadata": {
        "id": "uJUsCYT3tryl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell contains helper classes and functions needed for the main loop.\n",
        "# It includes the PropertyValidator for confirming numbers and functions for mask conversion.\n",
        "from typing import Dict, List, Optional, Union, Iterable, Tuple\n",
        "import cv2\n",
        "\n",
        "def xyxy_to_mask(boxes: np.ndarray, resolution_wh: Tuple[int, int]) -> np.ndarray:\n",
        "    width, height = resolution_wh\n",
        "    n = boxes.shape[0]\n",
        "    masks = np.zeros((n, height, width), dtype=bool)\n",
        "    for i, (x_min, y_min, x_max, y_max) in enumerate(boxes):\n",
        "        x_min, y_min = max(0, int(x_min)), max(0, int(y_min))\n",
        "        x_max, y_max = min(width - 1, int(x_max)), min(height - 1, int(y_max))\n",
        "        if x_max >= x_min and y_max >= y_min:\n",
        "            masks[i, y_min:y_max + 1, x_min:x_max + 1] = True\n",
        "    return masks\n",
        "\n",
        "def coords_above_threshold(matrix: np.ndarray, threshold: float) -> List[Tuple[int, int]]:\n",
        "    rows, cols = np.where(np.asarray(matrix) > threshold)\n",
        "    pairs = list(zip(rows.tolist(), cols.tolist()))\n",
        "    pairs.sort(key=lambda rc: matrix[rc[0], rc[1]], reverse=True)\n",
        "    return pairs\n",
        "\n",
        "def filter_segments_by_distance(mask: np.ndarray, distance_threshold: float = 300) -> np.ndarray:\n",
        "    mask_uint8 = mask.astype(np.uint8)\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_uint8, connectivity=8)\n",
        "    if num_labels <= 1: return mask.copy()\n",
        "    main_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
        "    main_centroid = centroids[main_label]\n",
        "    filtered_mask = np.zeros_like(mask, dtype=bool)\n",
        "    for label in range(1, num_labels):\n",
        "        if np.linalg.norm(centroids[label] - main_centroid) <= distance_threshold:\n",
        "            filtered_mask[labels == label] = True\n",
        "    return filtered_mask\n",
        "\n",
        "Value = Union[int, str, None]\n",
        "class PropertyValidator:\n",
        "    def __init__(self, n_consecutive: int):\n",
        "        self.n = n_consecutive\n",
        "        self._streak: Dict[int, int] = {}\n",
        "        self._last: Dict[int, Optional[str]] = {}\n",
        "        self._validated: Dict[int, Optional[str]] = {}\n",
        "\n",
        "    def _normalize(self, value: Value) -> Optional[str]:\n",
        "        if value is None: return None\n",
        "        s = str(value).strip()\n",
        "        return s if s else None\n",
        "\n",
        "    def update(self, tracker_ids: List[int], values: List[Value]):\n",
        "        for tid, raw in zip(tracker_ids, values):\n",
        "            if tid in self._validated and self._validated.get(tid) is not None: continue\n",
        "            val = self._normalize(raw)\n",
        "            if val is None:\n",
        "                self._streak[tid] = 0\n",
        "                continue\n",
        "            if self._last.get(tid) == val:\n",
        "                self._streak[tid] = self._streak.get(tid, 0) + 1\n",
        "            else:\n",
        "                self._streak[tid] = 1\n",
        "                self._last[tid] = val\n",
        "            if self._streak.get(tid, 0) >= self.n:\n",
        "                self._validated[tid] = self._last.get(tid)\n",
        "\n",
        "    def get_validated(self, tracker_ids: Iterable[int]) -> List[Optional[str]]:\n",
        "        return [self._validated.get(tid) for tid in tracker_ids]\n",
        "\n",
        "print(\"Helper utilities defined.\")"
      ],
      "metadata": {
        "id": "-GtaePfptr0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the main processing loop. It will take a few minutes to run.\n",
        "frames_history = []\n",
        "detections_history = []\n",
        "NUMBER_CLASS_ID = 2\n",
        "\n",
        "# Initialize validators\n",
        "number_validator = PropertyValidator(n_consecutive=3)\n",
        "team_validator = PropertyValidator(n_consecutive=1)\n",
        "\n",
        "# 1. Process the first frame to initialize trackers\n",
        "frame_generator = sv.get_video_frames_generator(str(SOURCE_VIDEO_PATH))\n",
        "frame = next(frame_generator)\n",
        "\n",
        "# Detect players and determine their teams\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.4, iou_threshold=0.9, class_agnostic_nms=True)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "detections = detections[np.isin(detections.class_id, PLAYER_CLASS_IDS)]\n",
        "TRACKER_IDS = list(range(1, len(detections.class_id) + 1))\n",
        "boxes = shrink_boxes(xyxy=detections.xyxy, scale=0.4)\n",
        "crops = [sv.crop_image(frame, box) for box in boxes]\n",
        "TEAMS = np.array(team_classifier.predict(crops))\n",
        "team_validator.update(tracker_ids=TRACKER_IDS, values=TEAMS)\n",
        "\n",
        "# Prompt SAM2.1 tracker with the initial player detections\n",
        "with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "    sam_predictor.load_first_frame(frame)\n",
        "    for xyxy, tracker_id in zip(detections.xyxy, TRACKER_IDS):\n",
        "        sam_predictor.add_new_prompt(frame_idx=0, obj_id=tracker_id, bbox=np.array([xyxy]))\n",
        "\n",
        "# 2. Loop through the rest of the video frames\n",
        "frame_generator = sv.get_video_frames_generator(str(SOURCE_VIDEO_PATH))\n",
        "for index, frame in tqdm(enumerate(frame_generator), desc=\"Processing video\"):\n",
        "    frame_h, frame_w, *_ = frame.shape\n",
        "\n",
        "    # Track players\n",
        "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "        tracker_ids, mask_logits = sam_predictor.track(frame)\n",
        "        masks = (mask_logits > 0.0).cpu().numpy().squeeze().astype(bool)\n",
        "        player_masks = np.array([filter_segments_by_distance(mask) for mask in masks])\n",
        "        player_detections = sv.Detections(\n",
        "            xyxy=sv.mask_to_xyxy(masks=player_masks),\n",
        "            mask=player_masks,\n",
        "            tracker_id=np.array(tracker_ids)\n",
        "        )\n",
        "\n",
        "    frames_history.append(frame)\n",
        "    detections_history.append(player_detections)\n",
        "\n",
        "    # Recognize numbers every 5 frames for efficiency\n",
        "    if index % 5 == 0:\n",
        "        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.4, iou_threshold=0.9)[0]\n",
        "        number_detections = sv.Detections.from_inference(result)\n",
        "        number_detections = number_detections[number_detections.class_id == NUMBER_CLASS_ID]\n",
        "        number_detections.mask = xyxy_to_mask(boxes=number_detections.xyxy, resolution_wh=(frame_w, frame_h))\n",
        "\n",
        "        number_crops = [sv.crop_image(frame, xyxy) for xyxy in sv.clip_boxes(sv.pad_boxes(xyxy=number_detections.xyxy, px=10), (frame_w, frame_h))]\n",
        "        numbers = [NUMBER_RECOGNITION_MODEL.predict(crop, NUMBER_RECOGNITION_MODEL_PROMPT)[0] for crop in number_crops]\n",
        "\n",
        "        # Match numbers to players using mask Intersection over Smaller area (IoS)\n",
        "        iou = sv.mask_iou_batch(player_masks, number_detections.mask, sv.OverlapMetric.IOS)\n",
        "        pairs = coords_above_threshold(iou, 0.9)\n",
        "        if len(pairs) > 0:\n",
        "            player_indices, number_indices = zip(*pairs)\n",
        "            matched_tracker_ids = [player_detections.tracker_id[i] for i in player_indices]\n",
        "            matched_numbers = [numbers[i] for i in number_indices]\n",
        "            number_validator.update(tracker_ids=matched_tracker_ids, values=matched_numbers)\n",
        "\n",
        "print(\"\\n‚úÖ Video processing complete.\")"
      ],
      "metadata": {
        "id": "ZjvCuxP4tr2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "e5003232-1b04-4bc2-a467-6f1d29c7f6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PropertyValidator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-58591817.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Initialize validators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnumber_validator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPropertyValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_consecutive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mteam_validator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPropertyValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_consecutive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PropertyValidator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "TARGET_VIDEO_PATH = HOME / f\"{SOURCE_VIDEO_PATH.stem}-result.mp4\"\n",
        "TARGET_VIDEO_COMPRESSED_PATH = HOME / f\"{SOURCE_VIDEO_PATH.stem}-result-compressed.mp4\"\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(str(SOURCE_VIDEO_PATH))\n",
        "\n",
        "# Set up annotators with team colors\n",
        "team_colors = sv.ColorPalette.from_hex([\n",
        "    TEAM_COLORS[TEAM_NAMES[0]],\n",
        "    TEAM_COLORS[TEAM_NAMES[1]]\n",
        "])\n",
        "team_mask_annotator = sv.MaskAnnotator(color=team_colors, opacity=0.5, color_lookup=sv.ColorLookup.INDEX)\n",
        "team_label_annotator = sv.RichLabelAnnotator(\n",
        "    font_path=f\"{HOME}/fonts/Staatliches-Regular.ttf\",\n",
        "    font_size=40, color=team_colors, text_color=sv.Color.WHITE,\n",
        "    text_position=sv.Position.BOTTOM_CENTER, text_offset=(0, 10),\n",
        "    color_lookup=sv.ColorLookup.INDEX\n",
        ")\n",
        "\n",
        "# Write the annotated frames to a new video file\n",
        "with sv.VideoSink(str(TARGET_VIDEO_PATH), video_info) as sink:\n",
        "    for frame, detections in tqdm(zip(frames_history, detections_history), desc=\"Generating final video\", total=len(frames_history)):\n",
        "        detections = detections[detections.area > 100]\n",
        "        if len(detections) == 0:\n",
        "            sink.write_frame(frame)\n",
        "            continue\n",
        "\n",
        "        # Get validated team and number for each player\n",
        "        teams = np.array(team_validator.get_validated(tracker_ids=detections.tracker_id)).astype(int)\n",
        "        numbers = np.array(number_validator.get_validated(tracker_ids=detections.tracker_id))\n",
        "\n",
        "        # Create labels with number and player name\n",
        "        labels = []\n",
        "        for number, team in zip(numbers, teams):\n",
        "            if number:\n",
        "                player_name = TEAM_ROSTERS[TEAM_NAMES[team]].get(number, \"\")\n",
        "                labels.append(f\"#{number} {player_name}\")\n",
        "            else:\n",
        "                labels.append(TEAM_NAMES[team])\n",
        "\n",
        "        # Annotate the frame\n",
        "        annotated_frame = frame.copy()\n",
        "        annotated_frame = team_mask_annotator.annotate(scene=annotated_frame, detections=detections, custom_color_lookup=teams)\n",
        "        annotated_frame = team_label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels, custom_color_lookup=teams)\n",
        "        sink.write_frame(annotated_frame)\n",
        "\n",
        "# Compress the video for easier viewing in Colab\n",
        "!ffmpeg -y -loglevel error -i {TARGET_VIDEO_PATH} -vcodec libx264 -crf 28 {TARGET_VIDEO_COMPRESSED_PATH}\n",
        "\n",
        "# Display the final result! üèÄ\n",
        "Video(TARGET_VIDEO_COMPRESSED_PATH, embed=True, width=1080)"
      ],
      "metadata": {
        "id": "oJ2HQRWStr5Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}